x <- x[!x %in% words.to.remove]
return(paste(x, collapse = " "))
}, simplify = "array", USE.NAMES = FALSE)
}
election.raw$county <- remove.words(election.raw$county, words.to.remove)
## read census data
census <- read_csv("census_county.csv")
#1.
#dimension
dim(election.raw)
#check missing
sum(is.na(election.raw))
#check unique numbers
length(unique(election.raw$state))
#2.
#dimension
dim(census)
#check missing
sum(is.na(census))
#check unique numbers of county
#election.raw
length(unique(election.raw$county))
#census
length(unique(census$County))
library(dplyr)
election.total = election.raw %>%
group_by(candidate,party) %>%
summarise(votes = sum(votes))
election.state = election.raw %>%
group_by(state,candidate,party) %>%
summarise(votes = sum(votes))
library(ggplot2)
df = arrange(election.total,votes)
df$votes_by_log = log(df$votes)
df0 = df[1:19,]
df2 = df[20:38,]
L1 = ggplot(df0, aes(x = reorder(candidate, votes_by_log, sum), y = votes_by_log)) + geom_col() + labs( x = "candidates",title ="all votes received by each candidate") + theme(axis.text=element_text(size=12),
axis.title=element_text(size=15,face="bold"), plot.title = element_text(size=17)) + coord_flip()
L2 = ggplot(df2, aes(x = reorder(candidate, votes_by_log, sum), y = votes_by_log)) + geom_col() + labs( x = "candidates")+ theme(axis.text=element_text(size=12),
axis.title=element_text(size=15,face="bold"), plot.title = element_text(size=17))+ coord_flip()
L2
L1
county_winner = election.raw %>% group_by(county) %>%
mutate(total=sum(votes), pct=votes/total) %>%
top_n(1)
state_winner = election.state %>% group_by(state) %>%
mutate(total=sum(votes), pct=votes/total) %>%
top_n(1)
states <- map_data("state")
ggplot(data = states) +
geom_polygon(aes(x = long, y = lat, fill = region, group = group),
color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE)  # color legend is unnecessary and takes too long
counties = map_data("county")
ggplot(data = counties) + geom_polygon(aes(x = long, y = lat,
fill = subregion, group = group), color = "white") +
coord_fixed(1.3) + guides(fill= FALSE)
state = state.name[match(states$region, tolower(state.name))]
states = states %>% mutate(state=state)
combined_states = left_join(states, state_winner, by="state")
ggplot(data = combined_states) + geom_polygon(aes(x = long, y = lat, fill = candidate, group = group)
, color = "white") + coord_fixed(1.3) + guides(fill= FALSE)
library(tidyverse)
counties <- map_data("county")
ca_county <- subset(counties, region == "california")
ca_county$county = ca_county$subregion
county_winner$county = tolower(county_winner$county)
countyPct = left_join(ca_county, county_winner, by = "county")
ggplot(data = countyPct) +
geom_polygon(aes(x = long, y = lat, fill = candidate, group = group),
color = "white") + coord_fixed(1.3) + guides(fill=FALSE)
census11 = na.omit(census) %>% mutate(Men = Men/TotalPop*100,
Employed = Employed/TotalPop*100,
Minority = Hispanic+Black+Native+Asian+Pacific) %>%
select(-Women, -Hispanic, -Native, -Black, -Asian, -Pacific, -Construction,-Walk, -PublicWork)
census11$county = tolower(census11$County)
county_winner$county = tolower(county_winner$county)
census1 = left_join(census11, county_winner, by = "county")
census1 = census1 %>% filter(candidate == "Joe Biden" | candidate == "Donald Trump")
res = census1 %>% group_by(candidate) %>%
summarise(White = mean(White),
Minority = mean(Minority),
Income = mean(Income),
Unemployment = mean(Unemployment),
Employed = mean(Employed),
Poverty = mean(Poverty),
Professional  =mean(Professional),
)
# To use the fmsb package, I have to add 2 lines to the dataframe: the max and min of each variable to show on the plot!
res <- rbind(c(0,100,100,70000,10,60,40,40),c(0,0,0,0,0,0,0), res)
library(fmsb)
# Color vector
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) , rgb(0.7,0.5,0.1,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4) , rgb(0.7,0.5,0.1,0.4) )
# plot with default options:
radarchart( res[,c(-1)]  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,20,5), cglwd=0.8,
#custom labels
vlcex=0.8
)
# Add a legend
legend(x=0.7, y=1, legend = res[-c(1,2),1]$candidate, bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)
census.clean = na.omit(census) %>% mutate(Men = Men/TotalPop*100,
Employed = Employed/TotalPop*100,
VotingAgeCitizen = VotingAgeCitizen/TotalPop*100,
Minority = Hispanic+Black+Native+Asian+Pacific) %>%
select(-Women, -Hispanic, -Native,
-Black, -Asian, -Pacific, -Construction,
-Walk, -PublicWork,-IncomePerCapErr,
-IncomeErr, -IncomePerCap)
head(census.clean,5)
pc.county = prcomp(census.clean[4:26], scale=TRUE, center = TRUE)
ct.pc = data.frame(pc.county$rotation[,1:2],features = rownames(pc.county$rotation))
library(kableExtra)
k1 = knitr::kable(ct.pc %>% top_n(3,abs(PC1)),caption = "largest three features of PC1 in ct.pc")
kable_styling(k1, "striped", position = "left", font_size = 9)
VE = pc.county$sdev^2
PVE = VE / sum(VE)
t = which(cumsum(PVE) >= 0.9)[1]
# PVE (scree) plot
p1 <- qplot(c(1:length(PVE)), PVE) +
geom_line() +
xlab("Principal Component") +
ylab("PVE") +
ggtitle("PVE Plot") +
ylim(0, 1)
# Cumulative PVE plot
p2 <- qplot(c(1:length(PVE)), cumsum(PVE)) +
geom_line() +
xlab("Principal Component") +
ylab(NULL) +
ggtitle("Cumulative PVE Plot") +
ylim(0,1)
library(gridExtra)
library(grid)
grid.arrange(p1, p2, ncol = 2, top = textGrob("Pca result",gp=gpar(fontsize = 16, font=3)))
hc.census = hclust(dist(scale(census.clean[4:26]), method="euclidean"), method="complete")
cluster_census = cutree(hc.census, k=10)
knitr::kable(t(table(cluster_census)),caption = "cluster_census")%>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=FALSE)
hc.census.pca = hclust(dist(scale(pc.county$x[,1:2]), method="euclidean"), method="complete")
cluster_census.pca = cutree(hc.census.pca, k=10)
knitr::kable(t(table(cluster_census.pca)),caption = "cluster_census.pca")%>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=FALSE)
t1 = cluster_census[which(census$County == "Santa Barbara County")]
t2 = cluster_census.pca[which(census$County == "Santa Barbara County")]
cluster1 = census %>% drop_na() %>% mutate(Cluster=cluster_census) %>% filter(Cluster == t1)
print("Not pca cluster of Santa Barbara county size")
dim(cluster1)[1]
cluster2 = census %>% drop_na() %>% mutate(Cluster=cluster_census.pca) %>% filter(Cluster == t2)
print("Ppca cluster of Santa Barbara county size")
dim(cluster2)[1]
# we move all state and county names into lower-case
county.winner = county_winner
tmpwinner <- county.winner %>% ungroup %>%
mutate_at(vars(state, county), tolower)
# we move all state and county names into lower-case
# we further remove suffixes of "county" and "parish"
tmpcensus <- census.clean %>% mutate_at(vars(State, County), tolower) %>%
mutate(County = gsub(" county|  parish", "", County))
# we join the two datasets
election.cl <- tmpwinner %>%
left_join(tmpcensus, by = c("state"="State", "county"="County")) %>%
na.omit
# drop levels of county winners if you haven't done so in previous parts
election.cl$candidate <- droplevels(election.cl$candidate)
## save meta information
election.meta <- election.cl %>% select(c(county, party, CountyId, state, votes, pct, total))
## save predictors and class labels
election.cl = election.cl %>% select(-c(county, party, CountyId, state, votes, pct, total))
election.pca.structure = election.cl %>% select(-c(candidate)) %>%
prcomp(scale=TRUE, center = TRUE)
election.pca = as_tibble(election.pca.structure$x)
colnames(election.pca) = colnames(election.pca.structure$x)
election.pca$candidate = election.cl$candidate
set.seed(10)
n <- nrow(election.cl)
idx.tr <- sample.int(n, 0.8*n)
election.tr <- election.cl[idx.tr, ]
election.pca.tr<- election.pca[idx.tr, ]
election.te <- election.cl[-idx.tr, ]
election.pca.te <- election.pca[-idx.tr, ]
set.seed(20)
nfold <- 10
folds <- sample(cut(1:nrow(election.tr), breaks=nfold, labels=FALSE))
calc_error_rate = function(predicted.value, true.value){
return(mean(true.value!=predicted.value))
}
records = matrix(NA, nrow=5, ncol=2)
colnames(records) = c("train.error","test.error")
rownames(records) = c("tree","logistic","lasso","knn","random forest")
library(tree)
library(maptree)
#get the X and Y
trnX = election.tr %>% select(-candidate)
trnY = election.tr %>% select(candidate)
tstX = election.te %>% select(-candidate)
tstY = election.te %>% select(candidate)
#creating the original tree from training data
origTree = tree(candidate~.,election.tr)
# using cross validation to find best size
cvtree = cv.tree(origTree, rand=folds, FUN=prune.misclass)
best.cv = min(cvtree$size[which(cvtree$dev==min(cvtree$dev))])
# Plot size vs. cross-validation error rate
plot(cvtree$size , cvtree$dev, type="b",
xlab = "Number of leaves, \'best\'", ylab = "CV Misclassification Error",
col = "red", main="CV")
abline(v=best.cv, lty=2)
draw.tree(origTree, nodeinfo=TRUE, cex = 0.9)
title("decision tree on Training Set", cex = 0.8)
# Prune tree.all
pt.cv = prune.misclass(origTree, best=best.cv)
# Plot pruned tree
draw.tree(pt.cv, nodeinfo=TRUE, cex = 0.9)
title("cutted Tree Built on Training Set")
# training error
pred.tree.trn = predict(pt.cv, trnX, type="class")
train.errort = calc_error_rate(pred.tree.trn, trnY$candidate)
# test error
pred.tree.tst = predict(pt.cv, tstX, type="class")
test.errort = calc_error_rate(pred.tree.tst, tstY$candidate)
# save errors
records[1,1] = train.errort
records[1,2] = test.errort
glm.fit <- glm(candidate~., data = election.tr, family = binomial)
summary(glm.fit)
logistic.train.prob = predict(glm.fit, trnX, type="response")
logistic.train.pred = rep("Donald Trump",
length(trnY$candidate))
logistic.train.pred[logistic.train.prob > 0.5]="Joe Biden"
train.error.logistic =
calc_error_rate(logistic.train.pred, trnY$candidate)
logistic.test.prob = predict(glm.fit, tstX, type="response")
logistic.test.pred = rep("Donald Trump",
length(tstY$candidate))
logistic.test.pred[logistic.test.prob > 0.5]="Joe Biden"
test.error.logistic = calc_error_rate(logistic.test.pred, tstY$candidate)
records[2,1] = train.error.logistic
records[2,2] = test.error.logistic
library(glmnet)
lasso.fit = cv.glmnet(x = as.matrix(trnX), y = droplevels(trnY$candidate), type.measure="auc",family = "binomial",alpha = 1, lambda = seq(1, 50) * 1e-4, foldid = folds)
t1 = as.matrix(coef.relaxed(lasso.fit$glmnet.fit))[,43]
t1
print("compare the logistic and lasso difference")
t1-glm.fit$coefficients
invlogit = function(t){
return(exp(t)/(1+exp(t)))
}
X = as.matrix(trnX)
X = cbind(rep(1,length(X[,1])),X)
lasso.train.prob = sapply(X %*%  t1, invlogit)
lasso.train.pred = rep("Donald Trump", length(trnY$candidate))
lasso.train.pred[lasso.train.prob > 0.5]="Joe Biden"
train.error.lasso = calc_error_rate(lasso.train.pred, trnY$candidate)
#test error
X = as.matrix(tstX)
X = cbind(rep(1,length(X[,1])),X)
lasso.test.prob = sapply(X %*% t1, invlogit)
lasso.test.pred = rep("Donald Trump", length(tstY$candidate))
lasso.test.pred[lasso.test.prob > 0.5]="Joe Biden"
test.error.lasso = calc_error_rate(lasso.test.pred, tstY$candidate)
records[3,1] = train.error.lasso
records[3,2] = test.error.lasso
df = data.frame(predictionT = predict(pt.cv, tstX, type="vector")[,2], predictionL = logistic.test.prob, predictionLasso = lasso.test.prob, labels = droplevels(tstY$candidate))
ggplot(df,aes(d = labels))+
geom_roc(aes(m = predictionT,d = labels,color = "blue"),n.cuts=20,labels=FALSE) +
geom_roc(aes(m = predictionL,d = labels,color = "black"),n.cuts=20,labels=FALSE)+
geom_roc(aes(m = predictionLasso,d = labels,color = "red"),n.cuts=20,labels=FALSE) +
style_roc(theme = theme_grey) +
ggtitle("ROC curves") + scale_colour_manual(
values = c("black","blue","red"),
labels = c("Logistic","Tree", "Lasso")
)
library(class)
library(reshape2)
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
train = (folddef!=chunkid)
Xtr = Xdat[train,]
Ytr = Ydat[train]
Xvl = Xdat[!train,]
Yvl = Ydat[!train]
## get classifications for current training chunks
predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
## get classifications for current test chunk
predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
data.frame(fold=chunkid,
train.error = calc_error_rate(predYtr, Ytr),
val.error = calc_error_rate(predYvl, Yvl))
}
kvec <- c(seq(1,9,length.out = 5),seq(15, 105, length.out=19))
kerrors <- NULL
for (j in kvec) {
tve <- plyr::ldply(1:nfold, do.chunk, folddef=folds,
Xdat=trnX, Ydat=trnY$candidate, k=j)
tve$neighbors <- j
kerrors <- rbind(kerrors, tve)
}
errors <- melt(kerrors, id.vars=c("fold","neighbors"), value.name="error")
val.error.means <- errors %>%
filter(variable=="val.error") %>%
group_by(neighbors) %>%
summarise_at(vars(error),funs(mean))
# picking the best k
min.error <- val.error.means %>%
filter(error==min(error))
bestk <- max(min.error$neighbors)
# calculating training errors at each k
# (by taking mean of each cv result)
train.error.means <- errors %>%
filter(variable=="train.error") %>%
group_by(neighbors) %>%
summarise_at(vars(error),funs(mean))
# plotting
ggplot(train.error.means) +
geom_line(aes(neighbors,error)) +
ggtitle("Training Error vs Number of Neighbors")
ggplot(val.error.means) +
geom_line(aes(neighbors,error)) +
ggtitle("Validation Error vs Number of Neighbors")
# training errors
pred.knn.train <- knn(train=trnX, test=trnX, cl=trnY$candidate, k=bestk)
train.errork <- calc_error_rate(pred.knn.train, trnY$candidate)
# test errors
pred.knn.test <- knn(train=trnX, test=tstX, cl=trnY$candidate, k=bestk)
test.errork <- calc_error_rate(pred.knn.test, tstY$candidate)
# adding to records
records[4,1] <- train.errork
records[4,2] <- test.errork
library(randomForest)
model <- randomForest(formula = droplevels(as.factor(candidate)) ~.,data = election.tr)
print(model)
# training errors
forest.predict.train <- predict(model, trnX)
label = droplevels(trnY$candidate)
train.errorRf <- calc_error_rate(forest.predict.train, label)
# test errors
forest.predict.test <- predict(model, tstX)
test.errorRf <- calc_error_rate(forest.predict.test, label)
records[5,1] <- train.errorRf
records[5,2] <- test.errorRf
# KNN on pca
trnX = election.pca.tr %>% select(-candidate)
trnY = election.pca.tr %>% select(candidate)
tstX = election.pca.te %>% select(-candidate)
tstY = election.pca.te %>% select(candidate)
#creating the original tree from training data
origTree = tree(candidate~.,election.pca.tr)
# using cross validation to find best size
cvtree = cv.tree(origTree, rand=folds, FUN=prune.misclass)
best.cv = min(cvtree$size[which(cvtree$dev==min(cvtree$dev))])
pt.cv = prune.misclass(origTree, best=best.cv)
pred.tree.trn = predict(pt.cv, trnX, type="class")
train.errort = calc_error_rate(pred.tree.trn, trnY$candidate)
# test error
pred.tree.tst = predict(pt.cv, tstX, type="class")
test.errort = calc_error_rate(pred.tree.tst, tstY$candidate)
pcarecords = matrix(NA, nrow=5, ncol=2)
colnames(pcarecords) = c("train.error","test.error")
rownames(pcarecords) = c("tree","logistic","lasso","knn","random forest")
# save errors
pcarecords[1,1] = train.errort
pcarecords[1,2] = test.errort
# Logistic on pca
glm.fit <- glm(candidate~., data = election.pca.tr, family = binomial)
#summary(glm.fit)
logistic.train.prob = predict(glm.fit, trnX, type="response")
logistic.train.pred = rep("Donald Trump",
length(trnY$candidate))
logistic.train.pred[logistic.train.prob > 0.5]="Joe Biden"
train.error.logistic =
calc_error_rate(logistic.train.pred, trnY$candidate)
logistic.test.prob = predict(glm.fit, tstX, type="response")
logistic.test.pred = rep("Donald Trump",
length(tstY$candidate))
logistic.test.pred[logistic.test.prob > 0.5]="Joe Biden"
test.error.logistic = calc_error_rate(logistic.test.pred, tstY$candidate)
pcarecords[2,1] = train.error.logistic
pcarecords[2,2] = test.error.logistic
#Lasso on PCA
lasso.fit = cv.glmnet(x = as.matrix(trnX), y = droplevels(trnY$candidate), type.measure="auc",family = "binomial",alpha = 1, lambda = seq(1, 50) * 1e-4, foldid = folds)
X = as.matrix(trnX)
X = cbind(rep(1,length(X[,1])),X)
t1 = as.matrix(coef.relaxed(lasso.fit$glmnet.fit))[,
lasso.fit$glmnet.fit$lambda == lasso.fit$lambda.min]
lasso.train.prob = sapply(X %*%  t1, invlogit)
lasso.train.pred = rep("Donald Trump", length(trnY$candidate))
lasso.train.pred[lasso.train.prob > 0.5]="Joe Biden"
train.error.lasso = calc_error_rate(lasso.train.pred, trnY$candidate)
#test error
X = as.matrix(tstX)
X = cbind(rep(1,length(X[,1])),X)
lasso.test.prob = sapply(X %*% t1, invlogit)
lasso.test.pred = rep("Donald Trump", length(tstY$candidate))
lasso.test.pred[lasso.test.prob > 0.5]="Joe Biden"
test.error.lasso = calc_error_rate(lasso.test.pred, tstY$candidate)
pcarecords[3,1] = train.error.lasso
pcarecords[3,2] = test.error.lasso
## KNN
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
train = (folddef!=chunkid)
Xtr = Xdat[train,]
Ytr = Ydat[train]
Xvl = Xdat[!train,]
Yvl = Ydat[!train]
## get classifications for current training chunks
predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
## get classifications for current test chunk
predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
data.frame(fold=chunkid,
train.error = calc_error_rate(predYtr, Ytr),
val.error = calc_error_rate(predYvl, Yvl))
}
kvec <- c(seq(1,9,length.out = 5),seq(15, 105, length.out=19))
kerrors <- NULL
for (j in kvec) {
tve <- plyr::ldply(1:nfold, do.chunk, folddef=folds,
Xdat=trnX, Ydat=trnY$candidate, k=j)
tve$neighbors <- j
kerrors <- rbind(kerrors, tve)
}
errors <- melt(kerrors, id.vars=c("fold","neighbors"), value.name="error")
val.error.means <- errors %>%
filter(variable=="val.error") %>%
group_by(neighbors) %>%
summarise_at(vars(error),funs(mean))
# picking the best k
min.error <- val.error.means %>%
filter(error==min(error))
bestk <- max(min.error$neighbors)
# calculating training errors at each k
# (by taking mean of each cv result)
train.error.means <- errors %>%
filter(variable=="train.error") %>%
group_by(neighbors) %>%
summarise_at(vars(error),funs(mean))
# training errors
pred.knn.train <- knn(train=trnX, test=trnX, cl=trnY$candidate, k=bestk)
train.errork <- calc_error_rate(pred.knn.train, trnY$candidate)
# test errors
pred.knn.test <- knn(train=trnX, test=tstX, cl=trnY$candidate, k=bestk)
test.errork <- calc_error_rate(pred.knn.test, tstY$candidate)
# adding to records
pcarecords[4,1] <- train.errork
pcarecords[4,2] <- test.errork
##
model <- randomForest(formula = droplevels(as.factor(candidate)) ~.,data = election.pca.tr)
print(model)
# training errors
forest.predict.train <- predict(model, trnX)
label = droplevels(trnY$candidate)
train.errorRf <- calc_error_rate(forest.predict.train, label)
# test errors
forest.predict.test <- predict(model, tstX)
test.errorRf <- calc_error_rate(forest.predict.test, label)
pcarecords[5,1] <- train.errorRf
pcarecords[5,2] <- test.errorRf
kable(records,caption = "Original data") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=FALSE)
kable(pcarecords,caption = "PCA result") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=FALSE)
kable(records-pcarecords,caption = "Original - PCA error rate") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=FALSE)
election.pca.te
election.pca.te
trnX
tstX
glm.fit
X
election.te
bestk
summary(glm.fit)
records
df <- read.csv("titanic.csv")
df
library(DBI)
conn <- dbConnect(RSQLite::SQLite(), "titanic.db")
dbWriteTable(conn, "titanic", df, overwrite =TRUE)
df$Survived
dbGetQuery(conn,'SELECT Age
FROM titanic
WHERE (Survived = 1)')
dbGetQuery(conn,'SELECT Avg(Age)
FROM titanic
WHERE (Survived = 1)')
dbListFields(conn)
/dbListFields
ï¼ŸdbListFields
?dbListFields
dbListFields(conn,titanic)
dbListFields(conn,'titanic')
PRODUCT = read.table("PRODUCT.txt",sep = ",",header  = T)
dbWriteTable(conn, "PRODUCT", PRODUCT, overwrite =TRUE)
PRODUCT
dbSendQuery(conn,'CREATE TABLE NEW_TABLE_NAME AS
SELECT *
FROM PRODUCT')
conn
dbSendStatement(conn,'INSERT INTO NEW_TABLE_NAME
VALUES ("p9", "SOCKS", "ORANGE")')
dbGetQuery(conn,'SELECT *
FROM NEW_TABLE_NAME')
dbSendStatement(conn,'DELETE FROM NEWPRODUCT
WHERE PROD_NO = "p9"')
dbGetQuery(conn,'SELECT *
FROM PRODUCT')
dbGetQuery(conn,'SELECT *
FROM PRODUCT
WHERE 2')
dbGetQuery(conn,'SELECT *
FROM PRODUCT
LIMIT 1 OFFSET 1')
PRODUCT
?dbDisconnect
